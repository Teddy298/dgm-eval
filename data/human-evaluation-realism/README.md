<p align="center">
<a href="https://layer6.ai/"><img src="https://github.com/layer6ai-labs/DropoutNet/blob/master/logs/logobox.jpg" width="180"></a>
</p>

# Layer 6 Image Realism Dataset

This folder contains two datasets related to the human subject response data collected for the paper "Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models", as well as example notebooks to load and perform basic analysis on the data.

## Aggregated Data

Under the folder `data` we present the aggregated performance results per perticipant from our experiments. In total there were 41 experiments, each corresponding to a generative model.  In each experiment, one model's generated images were compared to the test set of the image dataset it was trained on. The data from the 41 experiments are divided into four csvs, one for each image dataset `["cifar10", "ffhq256", "imagenet256", "lsun256"]`.

Explanation of columns:
`id`: A unique id for each person who participated in the experiment
`model`: The model used to generate images. Equivalently, this tells us which experiment the data is from.
`num_correct`: The number of times the participant correctly guessed an image was real or generated. Each person was shown 200 images in total, half of which were real, the other half being generated by a single model.
`err_rt`: `num_correct` divided by 200.
`f_err_rt`: The number of correct answers when the presented image was fake (generated), divided by 100.
`r_err_rt`: The number of correct answers when the presented image was real, divided by 100.
`r_ans_rt`: The number of times the participant guessed "real", divided by 200.
`resp_time`: The total time in seconds the participant spent making their decisions on the 200 trials. Time taken was measured starting after the short image viewing period, until an answer was input by the participant.
`f_resp_time`: Reponse time in seconds for fake (generated) images.
`r_resp_time`: Reponse time in seconds for real images.


## Per-image Data

Under the folder `per-image-data` we present the aggregated results per image from our experiments. The data from the 41 experiments are divided into four csvs, one for each image dataset `["cifar10", "ffhq256", "imagenet256", "lsun256"]`.

Explanation of columns:
`model`: The model used to generate images. Equivalently, this tells us which experiment the data is from.
`generated`: Value of 1 when the image was generated from the `model`. Value of 0 when the image was real and from the test dataset. For example, within the `cifar10_labeled_data.csv`, all rows with `generated=0` are from the CIFAR10 test set.
`image_path`: File path to the image. The paths correspond to the datasets we have released under the following GDrive
`https://drive.google.com/drive/folders/1X0MFaUta90d3zF9xG4KchjR-8SE0cT_7`
`number_guesses`: The number of times this image was shown to a participant during our experiments. This value is often 0, since the sets of available images are much larger than the total number of individual responses collected from humans.
`number_guesses_generated`: The number of times a human participant guessed that this image was fake (generated).
`soft_label`: `number_guesses_generated` divided by `number_guesses`. Has a value of 0 if `number_guesses=0`. This can be used as a training label for downstream tasks, such as finetuning a generative model to create images that are more likely to be considered realistic by a human, or for training a model which predicts whether a human is likely to guess that an image is real vs. fake.